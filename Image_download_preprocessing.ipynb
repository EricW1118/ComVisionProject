{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 1. Install OpenCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip3 install opencv-python"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 2. Import libs needed below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "VjR-14TGMvJu"
      },
      "outputs": [],
      "source": [
        "# importing required libraries\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import requests # request img from web\n",
        "import shutil # save img locally\n",
        "import os\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import hashlib\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 3. Load the Pubfig url and convert it to pd.dataframe format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "q6NQ-JCVN35U"
      },
      "outputs": [],
      "source": [
        "# Read url file\n",
        "def read_data(file):\n",
        "    data = []\n",
        "    for line in open(file): \n",
        "        line = line.strip().split(\"\\t\")\n",
        "        data.append(line)\n",
        "        # break\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "df = read_data(\"dev.csv\")\n",
        "df.columns = [\"name\", \"number\", \"url\", \"rect\", \"class\"]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 4. Download the images from these urls in the dataframe loaded above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def remove_files(upper_dir=\"dev\"):\n",
        "    for folder in os.listdir(upper_dir):\n",
        "        folder_path = os.path.join(upper_dir, folder)\n",
        "        if os.path.isdir(folder_path):\n",
        "            shutil.rmtree(folder_path)\n",
        "            os.makedirs(folder_path)\n",
        "        else:\n",
        "            os.remove(folder_path)\n",
        "                    \n",
        "def download_image(row, upper_dir=\"dev\"):\n",
        "    folder_path = os.path.join(upper_dir, '_'.join(row[\"name\"].split(\" \")))\n",
        "    if not os.path.isdir(folder_path):\n",
        "        shutil.rmtree(folder_path)\n",
        "        os.makedirs(folder_path)\n",
        "    \n",
        "    filename = os.path.join(folder_path, row['class'] + '.jpg')\n",
        "    try:\n",
        "        response = requests.get(row['url'], timeout=20)\n",
        "        img = Image.open(BytesIO(response.content))\n",
        "        img.save(filename)\n",
        "        print('Image sucessfully Downloaded: ',filename)\n",
        "    except Exception as e:\n",
        "        print('Image (%s), url (%s) Couldn\\'t be retrieved because of %s' % (filename, row['url'], e))\n",
        "\n",
        "# download the images from the urls in the dataframe\n",
        "# df.apply(download_image, axis=1)\n",
        "# The downloading processing is time consuming, so we save the images locally and load them from local"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 5. Find and delete the duplicated images based on their md5 values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_md5(file_path):\n",
        "    with open(file_path, 'rb') as file:\n",
        "        md5_hash = hashlib.md5()\n",
        "        while chunk := file.read(4096):\n",
        "            md5_hash.update(chunk)\n",
        "    return md5_hash.hexdigest()\n",
        "\n",
        "def delete_image(file_path):\n",
        "    try:\n",
        "        os.remove(file_path)\n",
        "        print(f\"Deleted: {file_path}\")\n",
        "    except OSError as e:\n",
        "        print(f\"Error deleting {file_path}: {e}\")\n",
        "        \n",
        "# Remove the pictures that are the same\n",
        "def find_and_delete_duplicated_images(directory):\n",
        "    md5_map = {}\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            md5_of_file = calculate_md5(file_path)\n",
        "            if md5_of_file not in md5_map:\n",
        "                md5_map[md5_of_file] = file_path\n",
        "            else:\n",
        "                delete_image(file_path)\n",
        "                if os.path.isfile(md5_map[md5_of_file]):\n",
        "                    delete_image(md5_map[md5_of_file]) \n",
        "               \n",
        "find_and_delete_duplicated_images(\"dev\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 6. Crop the head area from the images processed above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_head_path(row, upper_dir=\"dev\"):\n",
        "    folder_path = os.path.join(upper_dir, '_'.join(row[\"name\"].split(\" \")))\n",
        "    filename = os.path.join(folder_path, row['class'] + '.jpg')\n",
        "    return filename\n",
        "\n",
        "def get_head_image(image_path, rect_str, save_path):\n",
        "    # Load the image\n",
        "    img = cv2.imread(image_path)\n",
        "    rect = [int(st) for st in rect_str.split(\",\")]\n",
        "    # Cut the rectangle\n",
        "    cut_img = img[rect[1]:rect[1]+rect[3], rect[0]:rect[0]+rect[2]]\n",
        "    # cut_img = img[rect[0]:rect[0]+rect[2], rect[1]:rect[1]+rect[3]]\n",
        "    # Save the cut image\n",
        "    # cv2.imwrite(save_path, cut_img)\n",
        "    return cut_img\n",
        "    \n",
        "def show_cv2_image(img):\n",
        "    image_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    plt.imshow(image_rgb)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "    \n",
        "def show_image_with_path(image_path):\n",
        "    show_cv2_image(cv2.imread(image_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if the column exists\n",
        "column_name = 'head_image_path'\n",
        "if column_name not in df.columns:\n",
        "    df[column_name] = ''\n",
        "# Iterate over rows in df and cut the head area as a new image\n",
        "for index, row in df.iterrows():\n",
        "    original_image_path = get_head_path(row)\n",
        "    print(original_image_path)\n",
        "    if os.path.isfile(original_image_path):\n",
        "        show_cv2_image(get_head_image(original_image_path, row['rect'], get_head_image))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
